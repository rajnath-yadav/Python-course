{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# About This Notebook\n",
    "In this last chapter of the course, **Exploring Data with pandas: Intermediate**, we will learn:\n",
    "- Select columns, rows and individual items using their integer location.\n",
    "- Use `pd.read_csv()` to read CSV files in pandas.\n",
    "- Work with integer axis labels.\n",
    "- How to use pandas methods to produce boolean arrays.\n",
    "- Use boolean operators to combine boolean comparisons to perform more complex analysis.\n",
    "- Use index labels to align data.\n",
    "- Use aggregation to perform advanced analysis using loops.\n",
    "***\n",
    "## 1. Reading CSV files with pandas(IMPORTANT)\n",
    "\n",
    "In the previous notebook about the fundamentals of exploring data with pandas, we worked with Fortune Global 500 dataset. In this chapter, we will learn how to use the `pandas.read_csv()` function to read in CSV files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Previously, we used the snippet below to read our CSV file into pandas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "f500 = pd.read_csv('../../../Data/csv/f500.csv', index_col=0)\n",
    "f500.index.name = None\n",
    "f500.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But if you look closely, you may see that the index axis labels are the values from the first column in the data set, **company**:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "company,rank,revenues,revenue_change\n",
    "Walmart,1,485873,0.8\n",
    "State Grid,2,315199,-4.4\n",
    "Sinopec Group,3,267518,-9.1\n",
    "China National Petroleum,4,262573,-12.3\n",
    "Toyota Motor,5,254694,7.7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will see that in the [`read_csv()` function](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html), the `index_col` parameter is optional from the official documentation. When we specify a value of `0`, the first column will be used as the row labels.\n",
    "\n",
    "Compare with the dataframe above, notice how the `f500` dataframe looks like if we remove the second line using `f500.index.name = None`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f500 = pd.read_csv('../../../Data/csv/f500.csv', index_col=0)\n",
    "f500.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do you see the text **company** above the index labels? This is the name of the first column in the CSV. This value is used as the **axis name** for the index axis in Pandas.\n",
    "\n",
    "You see that both the column and index axes can have names assigned to them. Originally, we accessed the name of the index axes and set it to `None`, that's why the dataframe didn't have a name for the index axis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3.5.1\n",
    "1. Use the `pandas.read_csv()` function to read the `f500.csv` CSV file as a pandas dataframe. Assign it to the variable name `f500`.\n",
    "    - Do not use the `index_col` parameter.\n",
    "2. Use the following code to insert the NaN values (missing values) into the `previous_rank` column: <br>\n",
    "````python\n",
    "f500.loc[f500[\"previous_rank\"] == 0, \"previous_rank\"] = np.nan\n",
    "````\n",
    "Remark: If you get a notice that `np` is not defined, you have to import NumPy by typing `import numpy as np`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start your code below:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Using iloc to select by integer position\n",
    "\n",
    "In the previous exercise we read our CSV file into pandas. But this time, we didn't use the `index_col` parameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f500 = pd.read_csv('../../../Data/csv/f500.csv')\n",
    "print(f500[['company', 'rank', 'revenues']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two significant differences with the approach that we just took above:\n",
    "- the **company** column is now included as a regular column, not as an index column\n",
    "- the **index labels** now start from `0` as **integers**\n",
    "\n",
    "This is the more conventional way how we should read in a dataframe, and we will be going with this method from now on.\n",
    "\n",
    "However, do you still remember how we worked with a dataframe with **string index labels**? We used `loc[]` to select the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For selecting rows and columns by their integer positions, we use `iloc[]`. Using `iloc[]` is almost identical to indexing with NumPy, with integer positions starting at `0` like ndarrays and Python lists.\n",
    "\n",
    "`DataFrame.iloc[]` behaves similarly to `DataFrame.loc[]`. The full syntax for `DataFrame.iloc[]`, in pseudocode, is: \n",
    "\n",
    "````python\n",
    "df.iloc[row_index, column_index]\n",
    "````\n",
    "\n",
    "To help you memorize the two syntaxes easier:\n",
    "- ``loc``: label based selection\n",
    "- ``iloc``: integer position based selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3.5.2\n",
    "1. Select just the fifth row of the `f500` dataframe. Assign the result to `fifth_row`.\n",
    "2. Select the value in the first row of the `company` column. Assign the result to `company_value`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start your code below:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Using iloc to select by integer position continued\n",
    "\n",
    "If we want to select the first column from our `f500` dataset, we need to use ``:``, a colon, to specify all rows, and then use the integer ``0`` to specify the first column, like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "first_column = f500.iloc[:,0]\n",
    "print(first_column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To specify a positional slice, try to use the same shortcut that we used with labels. Below is an example how we would select the rows between index positions one to four (inclusive):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_to_sixth_rows = f500[1:5]\n",
    "print(second_to_sixth_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pay attention to the fact that the row at index position `5` is not included, just as if we were slicing with a Python list or NumPy ndarray. Recall that `loc[]` handles slicing differently:\n",
    "\n",
    "- With `loc[]`, the ending slice **is** included.\n",
    "- With `iloc[]`, the ending slice **is not** included.\n",
    "\n",
    "The table below summarizes the usage of `DataFrame.iloc[]` and `Series.iloc[]` to select by integer position:\n",
    "\n",
    "|Select by integer position| Explicit Syntax| Shorthand Convention|\n",
    "|--|--|--|\n",
    "|Single column from dataframe|df.iloc[:,3]| |\n",
    "|List of columns from dataframe|df.iloc[:,[3,5,6]] | |\n",
    "|Slice of columns from dataframe|df.iloc[:,3:7]| |\n",
    "|Single row from dataframe|df.iloc[20]| |\n",
    "|List of rows from dataframe|df.iloc[[0,3,8]]| |\n",
    "|Slice of rows from dataframe|df.iloc[3:5]|df[3:5]|\n",
    "|Single items from series|s.iloc[8]|s[8]|\n",
    "|List of item from series |s.iloc[[2,8,1]]|s[[2,8,1]]|\n",
    "|Slice of items from series|s.iloc[5:10]|s[5:10]|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3.5.3\n",
    "1. Select the first three rows of the `f500` dataframe. Assign the result to `first_three_rows`.\n",
    "2. Select the first and seventh rows and the first five columns of the `f500` dataframe. Assign the result to `first_seventh_row_slice`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start your code below:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Using pandas methods to create boolean masks\n",
    "\n",
    "There are two methods that I want to introduce to you in this chapter, which are the `Series.isnull()` [method](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.isnull.html) and `Series.notnull()` [method](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.notnull.html). These two methods can be either used to select rows that contain null (or NaN) values or to select rows that do **not** contain null values.\n",
    "\n",
    "Let's first have a look at the `Series.isnull()` method, which is used to view rows with null values (i.e. missing values) in one column.\n",
    "Here is an example for the `revenue_change` column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rev_is_null = f500[\"revenue_change\"].isnull()\n",
    "print(rev_is_null.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that using `Series.isnull()` resulted in a boolean series. Just like in NumPy, we can use this series to filter our dataframe, `f500`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "f500 = pd.read_csv('../../../Data/csv/f500.csv')\n",
    "f500.index.name = None\n",
    "\n",
    "\n",
    "rev_change_null = f500[rev_is_null]\n",
    "print(rev_change_null[[\"company\", \"country\",\"sector\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3.5.4\n",
    "1. Use the `Series.isnull()` method to select all rows from `f500` that have a null value for the `profit_change` column. Select only the `company`, `profits`, and `profit_change` columns. Assign the result to `null_profit_change`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Start your code below:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Working with Integer Labels (OPTIONAL)\n",
    "\n",
    "Now let's check the difference between `DataFrame.loc[]` and `DataFrame.iloc[]` – what kind of different output will they provide?:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use `DataFrame.iloc[]`, and it will get us the following result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only works if you have completed task 3.5.4\n",
    "first_null_profit_change = null_profit_change.iloc[0]\n",
    "print(first_null_profit_change)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But `DataFrame.loc[]` will throw an error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_null_profit_change = null_profit_change.loc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get an error, telling us that **the label [0] is not in the [index]**. Remember that `DataFrame.loc[]` is used for label based selection:\n",
    "\n",
    "- ``loc``: label based selection\n",
    "- ``iloc``: integer position based selection\n",
    "\n",
    "We see that there is no row with a 0 label in the index, we got the error above. If we wanted to select a row using `loc[]`, we'd have to use the integer label for the first row — `5`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_null_profit_change = null_profit_change.loc[5]\n",
    "print(first_null_profit_change)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Pandas Index Alignment (OPTIONAL)\n",
    "Do you know that pandas has a very powerful aspect? --- Almost every operation will <b>align on the index labels</b>. Let's look at an example below to understand what this means. We have a dataframe named `food` and a series named `alt_name`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "d = {'fruit_veg': [\"fruit\", \"veg\", \"fruit\", \"veg\",\"veg\"], 'qty': [4, 2, 4, 1, 2]}\n",
    "food = pd.DataFrame(data=d)\n",
    "food.index = ['tomato', 'carrot', 'lime', 'corn','eggplant'] \n",
    "food"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt_name = pd.Series(['rocket', 'aubergine', 'maize'], index=[\"arugula\", \"eggplant\", \"corn\"])\n",
    "alt_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By observing the two dataframes above, we see that though the `food` dataframe and the `alt_name` series have different numbers of items, they share two of the same index labels which are `corn` and `eggplant`. However, these are in different orders. If we wanted to add `alt_name` as a new column in our `food` dataframe, we can use the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "food[\"alt_name\"] = alt_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we perform the code above, pandas will intentionally ignore the order of the ``alt_name`` series, and automatically align on the index labels.\n",
    "\n",
    "In addition, Pandas will also:\n",
    "\n",
    "- Discard any items that have an index that doesn't match the dataframe (like `arugula`).\n",
    "- Fill any remaining rows with `NaN`.\n",
    "\n",
    "Observe the result again carefully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Below is the result\n",
    "food"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You see that with every occasion, the pandas library will align on index, no matter if our index labels are strings or integers - this makes working with data from different sources much much easier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Using Boolean Operators (IMPORTANT)\n",
    "We can combine boolean arrays using **boolean operators**. In Python, these boolean operators are `and`, `or`, and `not`. But in pandas, there is a slight difference compared to Python. Take a look at the chart below: \n",
    "\n",
    "|pandas|Python equivalent|Meaning|\n",
    "|-|-|-|\n",
    "|a & b| a and b| True if both a and b are True, else False|\n",
    "| a \\| b| a or b| True if either a or b is True|\n",
    "|~a| not a | True if a is False, else False|\n",
    "\n",
    "Let's try to use the syntaxes in the table in the small example below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\"company\", \"revenues\", \"country\"]\n",
    "f500_sel = f500[cols].head()\n",
    "f500_sel.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to find the companies in `f500_sel` with more than 265 billion in revenue, and on top of that with headquarters located in China. We can achieve this by using two boolean comparisons like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "over_265 = f500_sel[\"revenues\"] > 265000\n",
    "china = f500_sel[\"country\"] == \"China\"\n",
    "print(over_265.head())\n",
    "print(china.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we can do next is to use the `&` operator to combine the two boolean arrays to get the actual boolean we want, like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = over_265 & china\n",
    "combined.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last but not least, we perform selection on our dataframe to get the final result like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "final_cols = [\"company\", \"revenues\"]\n",
    "result = f500_sel.loc[combined, final_cols]\n",
    "result.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the end result which fulfills all of our criteria.\n",
    "\n",
    "### Task 3.5.7\n",
    "Now try to do a similar task by yourself:\n",
    "1. Select all companies with revenues over **100 billion** and **negative profits** from the `f500` dataframe. Note that the entries in the profits column are given in millions of dollars (USD). The result should include all columns.\n",
    "    - Create a boolean array that selects the companies with revenues greater than 100 billion. Assign the result to `large_revenue`.\n",
    "    - Create a boolean array that selects the companies with profits less than `0`. Assign the result to `negative_profits`.\n",
    "    - Combine `large_revenue` and `negative_profits`. Assign the result to `combined`.\n",
    "    - Use combined to filter `f500`. Assign the result to `big_rev_neg_profit`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start your code below:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Sorting Values\n",
    "\n",
    "Now let's try to answer some more complicated questions about our data set. What if we wanted to find the company that employs the most people in China? How can we achieve this? We can first select all of the rows where the `country` column equals `China`, like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_rows = f500[f500[\"country\"] == \"China\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we can use the [`DataFrame.sort_values()` method](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.sort_values.html) to sort the rows on the employees column, like this:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_rows = selected_rows.sort_values(\"employees\")\n",
    "print(sorted_rows[[\"company\", \"country\", \"employees\"]].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `sort_values()` method will by default automatically sort the rows in ascending order — from smallest to largest.\n",
    "\n",
    "But if we want to sort the rows in descending order instead, we can achieve this by setting the `ascending` parameter to `False`, like this:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_rows = selected_rows.sort_values(\"employees\", ascending=False)\n",
    "print(sorted_rows[[\"company\", \"country\", \"employees\"]].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we see the Companies in China who employ the most people is China National Petroleum. \n",
    "\n",
    "Can you find out the same about Japanese company?\n",
    "### Task 3.5.8\n",
    "\n",
    "1. Find the companies headquartered in Japan with the largest number of employees.\n",
    "    - Select only the rows that have a country name equal to `Japan`.\n",
    "    - Use `DataFrame.sort_values()` to sort those rows by the `employees` column in descending order.\n",
    "    - Use `DataFrame.iloc[]` to select the first row from the sorted dataframe.\n",
    "    - Extract the company name from the index label `company` from the first row. Assign the result to `top_japanese_employer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start your code below:\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
